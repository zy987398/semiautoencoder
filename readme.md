# åŠç›‘ç£å­¦ä¹ æ¡†æ¶ (Semi-Supervised Learning Framework)

è¿™æ˜¯ä¸€ä¸ªç»“åˆæ·±åº¦å­¦ä¹ ï¼ˆå˜åˆ†è‡ªç¼–ç å™¨ï¼‰å’Œé›†æˆå­¦ä¹ çš„é«˜çº§åŠç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºå¤„ç†æ ‡è®°
æ•°æ®æœ‰é™çš„å›å½’é—®é¢˜ã€‚
## ğŸš€ GPUåŠ é€Ÿæ”¯æŒ

æœ¬æ¡†æ¶å®Œå…¨æ”¯æŒGPUåŠ é€Ÿè®­ç»ƒï¼Œå¯ä»¥æ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦ã€‚

### GPUç¯å¢ƒæ£€æŸ¥

é¦–å…ˆè¿è¡Œç¯å¢ƒæ£€æŸ¥è„šæœ¬ï¼š

```bash
python check_environment.py
```

è¿™å°†æ£€æŸ¥ï¼š
- Pythonç‰ˆæœ¬
- CUDAå®‰è£…
- PyTorch GPUæ”¯æŒ
- æ‰€æœ‰ä¾èµ–åŒ…
- ç³»ç»Ÿå†…å­˜å’ŒGPUå†…å­˜
- æ€§èƒ½æµ‹è¯•

### GPUä½¿ç”¨æŒ‡å—

1. **è‡ªåŠ¨GPUæ£€æµ‹**ï¼šæ¡†æ¶ä¼šè‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„GPUå¹¶ä½¿ç”¨
2. **æ‰‹åŠ¨æŒ‡å®šè®¾å¤‡**ï¼š
   ```python
   model = EnhancedSemiSupervisedEnsemble(device='cuda')  # å¼ºåˆ¶ä½¿ç”¨GPU
   model = EnhancedSemiSupervisedEnsemble(device='cpu')   # å¼ºåˆ¶ä½¿ç”¨CPU
   ```

3. **GPUä¼˜åŒ–è®­ç»ƒç¤ºä¾‹**ï¼š
   ```bash
   python gpu_example.py
   ```

### GPUæ€§èƒ½ä¼˜åŒ–

æ¡†æ¶åŒ…å«å¤šé¡¹GPUä¼˜åŒ–ï¼š
- **æ··åˆç²¾åº¦è®­ç»ƒ**ï¼šè‡ªåŠ¨ä½¿ç”¨FP16åŠ é€Ÿ
- **ä¼˜åŒ–çš„æ‰¹å¤§å°**ï¼šè‡ªåŠ¨è°ƒæ•´æ‰¹å¤§å°ä»¥æœ€å¤§åŒ–GPUåˆ©ç”¨ç‡
- **å†…å­˜ç®¡ç†**ï¼šè‡ªåŠ¨æ¸…ç†GPUå†…å­˜
- **å¤šGPUæ”¯æŒ**ï¼šæ”¯æŒDataParallelå¤šGPUè®­ç»ƒ

## é¡¹ç›®ç»“æ„

```
semi_supervised_learning/
â”‚
â”œâ”€â”€ config.py              # é…ç½®æ–‡ä»¶
â”œâ”€â”€ models/               # æ¨¡å‹ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vae.py            # å˜åˆ†è‡ªç¼–ç å™¨æ¨¡å‹
â”‚   â””â”€â”€ ensemble.py       # é›†æˆæ¨¡å‹
â”œâ”€â”€ core/                 # æ ¸å¿ƒåŠŸèƒ½
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ semi_supervised.py # åŠç›‘ç£å­¦ä¹ ä¸»ç±»
â”œâ”€â”€ utils/                # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_utils.py     # æ•°æ®å¤„ç†å·¥å…·
â”‚   â””â”€â”€ visualization.py  # å¯è§†åŒ–å·¥å…·
â”œâ”€â”€ run_pipeline.py       # ä¸»è¿è¡Œè„šæœ¬
â”œâ”€â”€ example_usage.py      # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ requirements.txt      # ä¾èµ–åŒ…åˆ—è¡¨
â””â”€â”€ README.md            # é¡¹ç›®è¯´æ˜
```

## ä¸»è¦ç‰¹æ€§

1. **æ·±åº¦ç‰¹å¾å­¦ä¹ **ï¼šä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨ä»æ ‡è®°å’Œæœªæ ‡è®°æ•°æ®ä¸­å­¦ä¹ æœ‰æ•ˆçš„ç‰¹å¾è¡¨ç¤º
2. **é›†æˆå­¦ä¹ **ï¼šç»“åˆå¤šä¸ªå¼ºå¤§çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆLightGBMã€XGBoostã€CatBoostã€NGBoostï¼‰
3. **ä¸ç¡®å®šæ€§ä¼°è®¡**ï¼šæä¾›é¢„æµ‹ä¸ç¡®å®šæ€§çš„é‡åŒ–ä¼°è®¡
4. **é«˜è´¨é‡ä¼ªæ ‡ç­¾**ï¼šé€šè¿‡å¤šé‡è¿‡æ»¤æœºåˆ¶ç¡®ä¿ä¼ªæ ‡ç­¾çš„è´¨é‡
5. **è¿­ä»£è‡ªè®­ç»ƒ**ï¼šé€æ­¥æ‰©å±•è®­ç»ƒé›†ï¼Œæé«˜æ¨¡å‹æ€§èƒ½

## å®‰è£…

### 1. å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®

```bash
git clone <repository-url>
cd semi_supervised_learning
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
venv\Scripts\activate  # Windows
```

### 3. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 4. ï¼ˆå¯é€‰ï¼‰å®‰è£…GPUç‰ˆæœ¬çš„PyTorch

å¦‚æœæ‚¨æœ‰NVIDIA GPUï¼Œè¯·è®¿é—® [PyTorchå®˜ç½‘](https://pytorch.org/get-started/locally/) é€‰æ‹©åˆé€‚çš„CUDAç‰ˆæœ¬å®‰è£…ã€‚

ä¾‹å¦‚ï¼Œå¯¹äºCUDA 11.8ï¼š
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### 5. éªŒè¯å®‰è£…

```bash
python check_environment.py
```

## å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®

å‡†å¤‡ä¸¤ä¸ªCSVæ–‡ä»¶ï¼š
- `labeled.csv`ï¼šåŒ…å«ç‰¹å¾åˆ—å’Œç›®æ ‡åˆ—ï¼ˆå¦‚ 'crack_length'ï¼‰
- `unlabeled.csv`ï¼šåªåŒ…å«ç‰¹å¾åˆ—

### 2. è¿è¡Œå®Œæ•´æµç¨‹

```bash
python run_pipeline.py --labeled_file labeled.csv --unlabeled_file unlabeled.csv --target_column crack_length
```

### 3. ä½¿ç”¨Pythonä»£ç 

```python
from core.semi_supervised import EnhancedSemiSupervisedEnsemble
from utils.data_utils import load_data
from run_pipeline import run_full_pipeline

# åŠ è½½æ•°æ®
X_labeled, y_labeled, X_unlabeled = load_data(
    'labeled.csv',
    'unlabeled.csv',
    target_column='crack_length'
)

# è¿è¡Œå®Œæ•´æµç¨‹
model = run_full_pipeline(
    X_labeled, y_labeled, X_unlabeled,
    verbose=True
)

# é¢„æµ‹æ–°æ•°æ®
predictions = model.predict(new_data)

# ä¿å­˜æ¨¡å‹
model.save_model('my_model.pkl')
```

## è¯¦ç»†ä½¿ç”¨æŒ‡å—

### 1. è‡ªå®šä¹‰é…ç½®

```python
# è‡ªå®šä¹‰VAEé…ç½®
autoencoder_config = {
    'latent_dims': [128, 64, 32],
    'dropout_rate': 0.3,
    'epochs': 500,
    'batch_size': 128,
    'learning_rate': 5e-4
}

# è‡ªå®šä¹‰é›†æˆæ¨¡å‹é…ç½®
ensemble_config = {
    'LightGBM': {
        'n_estimators': 2000,
        'learning_rate': 0.02,
        'num_leaves': 31
    },
    'XGBoost': {
        'n_estimators': 1000,
        'learning_rate': 0.05,
        'max_depth': 6
    }
}

# åˆ›å»ºæ¨¡å‹
model = EnhancedSemiSupervisedEnsemble(
    autoencoder_config=autoencoder_config,
    ensemble_config=ensemble_config
)
```

### 2. åˆ†æ­¥æ‰§è¡Œ

```python
# Step 1: ç‰¹å¾å·¥ç¨‹å’ŒVAEè®­ç»ƒ
model.step1_feature_engineering_and_autoencoder(X_labeled, X_unlabeled)

# Step 2: è®­ç»ƒé›†æˆæ¨¡å‹
model.step2_train_ensemble_with_encoded_features(X_labeled, y_labeled)

# Step 3: ç”Ÿæˆä¼ªæ ‡ç­¾
pseudo_X, pseudo_y, pseudo_uncertainties = model.step3_generate_high_quality_pseudo_labels(
    X_unlabeled
)

# Step 4: è¿­ä»£è‡ªè®­ç»ƒ
model.step4_iterative_self_training(
    X_labeled, y_labeled, X_unlabeled,
    n_iterations=3
)
```

### 3. ä¸ç¡®å®šæ€§åˆ†æ

```python
# è·å–é¢„æµ‹å’Œä¸ç¡®å®šæ€§
predictions, uncertainties, individual_preds = model.predict(
    X_test, 
    return_uncertainty=True
)

# å¯è§†åŒ–ä¸ç¡®å®šæ€§
from utils.visualization import plot_uncertainty_analysis
plot_uncertainty_analysis(y_test, predictions, uncertainties)
```

### 4. æ¨¡å‹è¯„ä¼°

```python
# è¯„ä¼°æ¨¡å‹æ€§èƒ½
metrics, predictions, uncertainties = model.evaluate(X_test, y_test)

print(f"RMSE: {metrics['ensemble']['RMSE']:.4f}")
print(f"RÂ²: {metrics['ensemble']['R2']:.4f}")
print(f"Mean Uncertainty: {metrics['uncertainty']['mean_uncertainty']:.4f}")
```

## å‘½ä»¤è¡Œå‚æ•°

è¿è¡Œ `python run_pipeline.py --help` æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‚æ•°ï¼š

- `--labeled_file`: æ ‡è®°æ•°æ®æ–‡ä»¶è·¯å¾„
- `--unlabeled_file`: æœªæ ‡è®°æ•°æ®æ–‡ä»¶è·¯å¾„
- `--target_column`: ç›®æ ‡åˆ—åç§°
- `--test_size`: æµ‹è¯•é›†æ¯”ä¾‹
- `--model_save_path`: æ¨¡å‹ä¿å­˜è·¯å¾„
- `--results_dir`: ç»“æœä¿å­˜ç›®å½•
- `--device`: ä½¿ç”¨çš„è®¾å¤‡ï¼ˆcuda/cpuï¼‰
- `--verbose`: æ‰“å°è¯¦ç»†ä¿¡æ¯

## è¾“å‡ºç»“æœ

è¿è¡Œå®Œæˆåï¼Œä¼šåœ¨æŒ‡å®šçš„ç»“æœç›®å½•ï¼ˆé»˜è®¤ä¸º `results/`ï¼‰ç”Ÿæˆï¼š

1. **æ¨¡å‹æ–‡ä»¶**ï¼š`semi_supervised_model.pkl`
2. **è¯„ä¼°æŒ‡æ ‡**ï¼š`test_metrics.json`
3. **é¢„æµ‹ç»“æœ**ï¼š`test_predictions.csv`
4. **å¯è§†åŒ–å›¾è¡¨**ï¼š
   - `training_history.png`ï¼šè®­ç»ƒå†å²
   - `predictions.png`ï¼šé¢„æµ‹å¯¹æ¯”å›¾
   - `residuals.png`ï¼šæ®‹å·®åˆ†æ
   - `model_comparison.png`ï¼šæ¨¡å‹æ€§èƒ½å¯¹æ¯”
   - `uncertainty_analysis.png`ï¼šä¸ç¡®å®šæ€§åˆ†æ

## å…³é”®å‚æ•°è¯´æ˜

### ä¼ªæ ‡ç­¾è¿‡æ»¤å‚æ•°

- `confidence_threshold`ï¼šä¸ç¡®å®šæ€§è¿‡æ»¤é˜ˆå€¼ï¼ˆé»˜è®¤0.85ï¼‰
- `reconstruction_threshold`ï¼šé‡å»ºè¯¯å·®è¿‡æ»¤é˜ˆå€¼ï¼ˆé»˜è®¤0.9ï¼‰
- `ensemble_agreement_threshold`ï¼šé›†æˆä¸€è‡´æ€§è¿‡æ»¤é˜ˆå€¼ï¼ˆé»˜è®¤0.8ï¼‰
- `min_pseudo_labels`ï¼šæ¯è½®æœ€å°‘ä¼ªæ ‡ç­¾æ•°ï¼ˆé»˜è®¤50ï¼‰

### è‡ªè®­ç»ƒå‚æ•°

- `n_iterations`ï¼šè‡ªè®­ç»ƒè¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤3ï¼‰
- `high_confidence_percentile`ï¼šé«˜ç½®ä¿¡åº¦ç™¾åˆ†ä½ï¼ˆé»˜è®¤50ï¼‰

## æ³¨æ„äº‹é¡¹

1. **æ•°æ®è´¨é‡**ï¼šç¡®ä¿è¾“å…¥æ•°æ®æ²¡æœ‰ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
2. **è®¡ç®—èµ„æº**ï¼šæ·±åº¦å­¦ä¹ éƒ¨åˆ†å¯ä»¥ä½¿ç”¨GPUåŠ é€Ÿ
3. **å†…å­˜ä½¿ç”¨**ï¼šå¤§æ•°æ®é›†å¯èƒ½éœ€è¦è¾ƒå¤šå†…å­˜
4. **æ¨¡å‹é€‰æ‹©**ï¼šå¯ä»¥æ ¹æ®å…·ä½“ä»»åŠ¡è°ƒæ•´ä½¿ç”¨çš„é›†æˆæ¨¡å‹

## æ•…éšœæ’é™¤

1. **å†…å­˜ä¸è¶³**ï¼šå‡å°‘æ‰¹é‡å¤§å°æˆ–ä½¿ç”¨æ›´å°‘çš„é›†æˆæ¨¡å‹
2. **è®­ç»ƒæ—¶é—´è¿‡é•¿**ï¼šå‡å°‘VAEè®­ç»ƒè½®æ•°æˆ–é›†æˆæ¨¡å‹æ•°é‡
3. **ä¼ªæ ‡ç­¾è¿‡å°‘**ï¼šé™ä½è¿‡æ»¤é˜ˆå€¼æˆ–æ£€æŸ¥æ•°æ®è´¨é‡
4. **é¢„æµ‹æ€§èƒ½å·®**ï¼šå¢åŠ æ ‡è®°æ•°æ®æˆ–è°ƒæ•´æ¨¡å‹å‚æ•°

## æ‰©å±•å’Œå®šåˆ¶

æ¡†æ¶è®¾è®¡çµæ´»ï¼Œæ˜“äºæ‰©å±•ï¼š

1. **æ·»åŠ æ–°æ¨¡å‹**ï¼šåœ¨ `ensemble.py` ä¸­çš„ `initialize_models` æ–¹æ³•æ·»åŠ 
2. **è‡ªå®šä¹‰è¿‡æ»¤å™¨**ï¼šåœ¨ `step3_generate_high_quality_pseudo_labels` ä¸­æ·»åŠ 
3. **æ–°çš„ç‰¹å¾å·¥ç¨‹**ï¼šä¿®æ”¹ `step1_feature_engineering_and_autoencoder`
4. **è‡ªå®šä¹‰å¯è§†åŒ–**ï¼šåœ¨ `visualization.py` ä¸­æ·»åŠ æ–°å‡½æ•°

## å‚è€ƒæ–‡çŒ®

æœ¬æ¡†æ¶åŸºäºä»¥ä¸‹æŠ€æœ¯ï¼š
- å˜åˆ†è‡ªç¼–ç å™¨ç‰¹å¾å­¦ä¹ 
- é›†æˆå­¦ä¹ 
- åŠç›‘ç£å­¦ä¹ 
- ä¸ç¡®å®šæ€§ä¼°è®¡

## è®¸å¯è¯

[æ·»åŠ æ‚¨çš„è®¸å¯è¯ä¿¡æ¯]

## è”ç³»æ–¹å¼

[æ·»åŠ æ‚¨çš„è”ç³»ä¿¡æ¯]