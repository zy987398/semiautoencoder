"""
ç¯å¢ƒæ£€æŸ¥è„šæœ¬ - éªŒè¯GPUå’Œä¾èµ–åŒ…è®¾ç½®
"""
import sys
import subprocess
import pkg_resources
import psutil

def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    print("=" * 60)
    print("Python Version Check")
    print("=" * 60)
    version = sys.version_info
    print(f"Python version: {version.major}.{version.minor}.{version.micro}")
    
    if version.major < 3 or (version.major == 3 and version.minor < 7):
        print("âš ï¸  WARNING: Python 3.7+ is recommended")
    else:
        print("âœ… Python version is compatible")


def check_cuda_installation():
    """æ£€æŸ¥CUDAå®‰è£…"""
    print("\n" + "=" * 60)
    print("CUDA Installation Check")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥nvidia-smi
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIA driver is installed")
            print("\nGPU Information:")
            # æå–GPUä¿¡æ¯
            lines = result.stdout.split('\n')
            for line in lines:
                if 'NVIDIA' in line and 'CUDA' in line:
                    print(line.strip())
        else:
            print("âŒ nvidia-smi not found. GPU driver may not be installed.")
    except FileNotFoundError:
        print("âŒ nvidia-smi command not found. NVIDIA driver is not installed.")
    
    # æ£€æŸ¥CUDAç‰ˆæœ¬
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            print("\nâœ… CUDA compiler is installed")
            # æå–CUDAç‰ˆæœ¬
            for line in result.stdout.split('\n'):
                if 'release' in line:
                    print(f"CUDA version: {line.strip()}")
        else:
            print("\nâš ï¸  CUDA compiler (nvcc) not found")
    except FileNotFoundError:
        print("\nâš ï¸  CUDA compiler (nvcc) not found")


def check_pytorch_gpu():
    """æ£€æŸ¥PyTorch GPUæ”¯æŒ"""
    print("\n" + "=" * 60)
    print("PyTorch GPU Support Check")
    print("=" * 60)
    
    try:
        import torch
        print(f"âœ… PyTorch version: {torch.__version__}")
        
        # æ£€æŸ¥CUDAå¯ç”¨æ€§
        if torch.cuda.is_available():
            print(f"âœ… CUDA is available in PyTorch")
            print(f"âœ… CUDA version (PyTorch): {torch.version.cuda}")
            print(f"âœ… Number of GPUs: {torch.cuda.device_count()}")
            
            # æ˜¾ç¤ºæ‰€æœ‰GPUä¿¡æ¯
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                print(f"\nGPU {i}: {torch.cuda.get_device_name(i)}")
                print(f"  - Compute capability: {props.major}.{props.minor}")
                print(f"  - Total memory: {props.total_memory / 1024**3:.2f} GB")
                print(f"  - Multiprocessors: {props.multi_processor_count}")
                
            # æµ‹è¯•GPUæ“ä½œ
            print("\nğŸ”§ Testing GPU operations...")
            try:
                # åˆ›å»ºå¼ é‡å¹¶ç§»åˆ°GPU
                x = torch.randn(1000, 1000).cuda()
                y = torch.randn(1000, 1000).cuda()
                z = torch.matmul(x, y)
                torch.cuda.synchronize()
                print("âœ… GPU tensor operations work correctly")
                
                # æ¸…ç†
                del x, y, z
                torch.cuda.empty_cache()
            except Exception as e:
                print(f"âŒ GPU operation failed: {e}")
        else:
            print("âŒ CUDA is NOT available in PyTorch")
            print("\nPossible reasons:")
            print("1. No NVIDIA GPU installed")
            print("2. NVIDIA driver not installed")
            print("3. PyTorch installed without CUDA support")
            print("\nTo install PyTorch with CUDA support:")
            print("Visit: https://pytorch.org/get-started/locally/")
            
    except ImportError:
        print("âŒ PyTorch is not installed")


def check_dependencies():
    """æ£€æŸ¥æ‰€æœ‰ä¾èµ–åŒ…"""
    print("\n" + "=" * 60)
    print("Dependencies Check")
    print("=" * 60)
    
    required_packages = [
        'torch', 'torchvision', 'numpy', 'pandas', 'scikit-learn',
        'lightgbm', 'xgboost', 'catboost', 'ngboost',
        'matplotlib', 'seaborn', 'joblib'
    ]
    
    installed_packages = {pkg.key for pkg in pkg_resources.working_set}
    
    all_installed = True
    for package in required_packages:
        if package in installed_packages:
            version = pkg_resources.get_distribution(package).version
            print(f"âœ… {package:15} {version}")
        else:
            print(f"âŒ {package:15} NOT INSTALLED")
            all_installed = False
    
    if all_installed:
        print("\nâœ… All required packages are installed")
    else:
        print("\nâŒ Some packages are missing. Run: pip install -r requirements.txt")


def check_memory():
    """æ£€æŸ¥ç³»ç»Ÿå†…å­˜"""
    print("\n" + "=" * 60)
    print("System Memory Check")
    print("=" * 60)
    
    try:

        
        # RAMä¿¡æ¯
        ram = psutil.virtual_memory()
        print(f"Total RAM: {ram.total / 1024**3:.2f} GB")
        print(f"Available RAM: {ram.available / 1024**3:.2f} GB")
        print(f"Used RAM: {ram.used / 1024**3:.2f} GB ({ram.percent}%)")
        
        # GPUå†…å­˜ä¿¡æ¯
        try:
            import torch
            if torch.cuda.is_available():
                print("\nGPU Memory:")
                for i in range(torch.cuda.device_count()):
                    props = torch.cuda.get_device_properties(i)
                    allocated = torch.cuda.memory_allocated(i) / 1024**3
                    reserved = torch.cuda.memory_reserved(i) / 1024**3
                    total = props.total_memory / 1024**3
                    
                    print(f"GPU {i}:")
                    print(f"  - Total: {total:.2f} GB")
                    print(f"  - Allocated: {allocated:.2f} GB")
                    print(f"  - Reserved: {reserved:.2f} GB")
                    print(f"  - Free: {total - reserved:.2f} GB")
        except:
            pass
            
    except ImportError:
        print("âš ï¸  psutil not installed. Cannot check system memory.")
        print("Install with: pip install psutil")


def performance_test():
    """ç®€å•çš„æ€§èƒ½æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("Performance Test")
    print("=" * 60)
    
    try:
        import torch
        import time
        
        # çŸ©é˜µå¤§å°
        sizes = [1000, 2000, 4000]
        
        for size in sizes:
            print(f"\nMatrix multiplication ({size}x{size}):")
            
            # CPUæµ‹è¯•
            x_cpu = torch.randn(size, size)
            y_cpu = torch.randn(size, size)
            
            start = time.time()
            z_cpu = torch.matmul(x_cpu, y_cpu)
            cpu_time = time.time() - start
            print(f"  CPU time: {cpu_time:.4f} seconds")
            
            # GPUæµ‹è¯•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if torch.cuda.is_available():
                x_gpu = x_cpu.cuda()
                y_gpu = y_cpu.cuda()
                
                # é¢„çƒ­
                _ = torch.matmul(x_gpu, y_gpu)
                torch.cuda.synchronize()
                
                start = time.time()
                z_gpu = torch.matmul(x_gpu, y_gpu)
                torch.cuda.synchronize()
                gpu_time = time.time() - start
                
                print(f"  GPU time: {gpu_time:.4f} seconds")
                print(f"  Speedup: {cpu_time/gpu_time:.2f}x")
                
                # æ¸…ç†
                del x_gpu, y_gpu, z_gpu
                torch.cuda.empty_cache()
            
            del x_cpu, y_cpu, z_cpu
            
    except Exception as e:
        print(f"Performance test failed: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” Semi-Supervised Learning Framework - Environment Check")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰æ£€æŸ¥
    check_python_version()
    check_cuda_installation()
    check_pytorch_gpu()
    check_dependencies()
    check_memory()
    performance_test()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("Summary")
    print("=" * 60)
    
    try:
        import torch
        if torch.cuda.is_available():
            print("âœ… GPU is available and configured correctly!")
            print("ğŸš€ You can use GPU acceleration for training.")
        else:
            print("âš ï¸  GPU is not available.")
            print("ğŸ’¡ Training will use CPU (slower but still functional).")
    except:
        print("âŒ PyTorch is not installed correctly.")
    
    print("\nğŸ“ To use GPU acceleration:")
    print("1. Ensure you have an NVIDIA GPU")
    print("2. Install NVIDIA drivers")
    print("3. Install PyTorch with CUDA support")
    print("4. Run your training script")


if __name__ == "__main__":
    main()
